# ğŸ¥ Video Transcription & Metadata Annotation System

## ğŸ“Œ Overview
This project is a Video Intelligence system that processes recorded video calls and produces:
- Timestamped speech transcription
- Emotion analysis from audio
- Delivery nuance analysis (tone, pace, confidence)
- Reaction annotations per transcript segment
- A concise conversation summary

The system is built using Python, Streamlit, and pretrained speech models, and is designed to demonstrate multimodal AI processing of video data.

---

## ğŸ—ï¸ System Architecture

Video Upload
â†“
Audio Extraction (MoviePy)
â†“
Speech Transcription (SpeechBrain ASR)
â†“
Emotion Analysis (Wav2Vec2 Emotion Model)
â†“
Delivery Nuance Analysis
â†“
Reaction Annotation (Text-based)
â†“
LLM-based Summarization
â†“
Final JSON Output + Streamlit UI


---

## ğŸ§© Components Breakdown

### 1. Transcription Module
- Converts extracted audio into timestamped text segments
- Uses pretrained SpeechBrain ASR models

### 2. Emotion Annotation
- Detects emotions from speech audio
- Outputs probability-based emotion labels

### 3. Delivery Nuances
- Analyzes speech pace, pauses, and tone
- Helps understand how something was said, not just what

### 4. Reaction Annotation
- Assigns conversational reactions per transcript segment
- Examples: agreement, hesitation, confidence, uncertainty

### 5. Summarization
- Generates a concise summary of the conversation
- Based on the full transcript text

---

## ğŸ–¥ï¸ Tech Stack

- **Python 3.10**
- **Streamlit** â€“ Web UI
- **SpeechBrain** â€“ ASR & Emotion Recognition
- **MoviePy** â€“ Audio extraction from video
- **PyTorch** â€“ Model inference
- **Altair / Pandas** â€“ Data handling

---

## âš™ï¸ Setup Instructions

### 1. Clone or Download Repository
```bash
git clone <repository-url>
cd video-transcription-metadata-annotation


2. Create Virtual Environment
python -m venv venv
source venv/bin/activate  # macOS/Linux

3. Install Dependencies
pip install -r requirements.txt

4. Run the Application
streamlit run app.py

ğŸš€ Usage Guidelines

Launch the Streamlit app

Upload a video file (.mp4, .mov, .avi)

The system will:

Extract audio

Generate timestamped transcript

Annotate emotions, delivery, and reactions

Produce a summary

Final output is saved as:
outputs/final_output.json


Project Structure:

â”œâ”€â”€ app.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ transcribe_video.py
â”‚   â”œâ”€â”€ annotate_emotions.py
â”‚   â”œâ”€â”€ delivery_nuances.py
â”‚   â”œâ”€â”€ reaction_annotations.py
â”‚   â””â”€â”€ summarize_with_llm.py
â”œâ”€â”€ outputs/
â”œâ”€â”€ inputs/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore

Example Output

Timestamped transcript with annotations

Emotion and delivery metadata

Reaction labels

Conversation summary

Structured JSON output
